{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "--[[ this is the \"60 min blitz\" deep learning Torch tutorial\n",
    "    from https://github.com/soumith/cvpr2015/blob/master/Deep%20Learning%20with%20Torch.ipynb\n",
    "    I've eliminated the cuda stuff in this nb bc I'm running w/o\n",
    "    it. I'll put another file in this folder eventually which includes\n",
    "    only the cuda stuff and run it on an AWS GPU instance']]--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = torch.Tensor(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 6.4703e-317  6.9466e-310   0.0000e+00   0.0000e+00\n",
       "  0.0000e+00  4.8234e+228   7.4240e-38   1.8359e-76\n",
       "  3.9136e+20   9.9636e-43  1.7054e+256  5.4911e-143\n",
       " 2.1403e+161  3.9845e+252   1.1761e-47   6.9767e-76\n",
       "  5.0679e-86   4.2631e-96  5.2308e-143   4.7666e-38\n",
       "[torch.DoubleTensor of size 5x4]\n",
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 5\n",
       " 4\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b -- # === size() operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 5\n",
       " 4\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b:size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "[string \"net = nn.Sequential()...\"]:16: attempt to call method '_tostring' (a nil value)\nstack traceback:\n\t[string \"net = nn.Sequential()...\"]:16: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/gram/torch/install/share/lua/5.1/itorch/main.lua:210: in function </home/gram/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/home/gram/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/home/gram/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/home/gram/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/home/gram/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/gram/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00405d50",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"net = nn.Sequential()...\"]:16: attempt to call method '_tostring' (a nil value)\nstack traceback:\n\t[string \"net = nn.Sequential()...\"]:16: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/gram/torch/install/share/lua/5.1/itorch/main.lua:210: in function </home/gram/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/home/gram/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/home/gram/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/home/gram/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/home/gram/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/gram/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00405d50"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialConvolution(1,6,5,5))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.SpatialConvolution(6,16,5,5))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(16*5*5))\n",
    "net:add(nn.Linear(16*5*5,120))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.Linear(120,84))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.Linear(84,10))\n",
    "net:add(nn.LogSoftMax())\n",
    "\n",
    "print('Lenet5\\n' .. net:_tostring());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = torch.rand(1,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = net:forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.2464\n",
       "-2.3324\n",
       "-2.2079\n",
       "-2.2634\n",
       "-2.2930\n",
       "-2.4218\n",
       "-2.3295\n",
       "-2.2321\n",
       "-2.3854\n",
       "-2.3351\n",
       "[torch.DoubleTensor of size 10]\n",
       "\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net:zeroGradParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradInput = net:backward(input, torch.rand(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  1\n",
       " 32\n",
       " 32\n",
       "[torch.LongStorage of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(#gradInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion()\n",
    "criterion:forward(output, 3)\n",
    "gradients = criterion:backward(output, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradInput = net:backward(input, gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,1,.,.) = \n",
       "  0.0422 -0.0101\n",
       " -0.0428  0.3090\n",
       "\n",
       "(2,1,.,.) = \n",
       "  0.3576  0.3646\n",
       "  0.2864  0.4519\n",
       "\n",
       "(3,1,.,.) = \n",
       "  0.2387 -0.3381\n",
       "  0.3300  0.1888\n",
       "[torch.DoubleTensor of size 3x1x2x2]\n",
       "\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.SpatialConvolution(1,3,2,2)\n",
    "print(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.4620\n",
       " 0.0383\n",
       " 0.2441\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- train an nn to learn what's in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'paths';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Archive:  cifar10torchsmall.zip\n",
       "  inflating: cifar10-test.t7         "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  inflating: cifar10-train.t7        "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (not paths.filep(\"cifar10torchsmall.zip\")) then\n",
    "    os.execute('wget -c https://s3.amazonaws.com/torch7/data/cifar10torchsmall.zip')\n",
    "    os.execute('unzip cifar10torchsmall.zip')\n",
    "end\n",
    "trainset = torch.load('cifar10-train.t7')\n",
    "testset = torch.load('cifar10-test.t7')\n",
    "classes = {'airplane', 'automobile','bird','cat','deer','dog',\n",
    "            'frog','horse','ship','truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  data : ByteTensor - size: 10000x3x32x32\n",
       "  label : ByteTensor - size: 10000\n",
       "}\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10000\n",
       "     3\n",
       "    32\n",
       "    32\n",
       "[torch.LongStorage of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(#trainset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "automobile\t\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itorch.image(trainset.data[100])\n",
    "print(classes[trainset.label[100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- clean the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "setmetatable(trainset, \n",
    "    {__index = function(t, i) \n",
    "                    return {t.data[i], t.label[i]} \n",
    "                end}\n",
    ");\n",
    "trainset.data = trainset.data:double() -- convert the data from a ByteTensor to a DoubleTensor.\n",
    "\n",
    "function trainset:size() \n",
    "    return self.data:size(1) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000\t\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainset:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "[string \"print(testset:size())...\"]:1: attempt to call method 'size' (a nil value)\nstack traceback:\n\t[string \"print(testset:size())...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/gram/torch/install/share/lua/5.1/itorch/main.lua:210: in function </home/gram/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/home/gram/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/home/gram/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/home/gram/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/home/gram/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/gram/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00405d50",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"print(testset:size())...\"]:1: attempt to call method 'size' (a nil value)\nstack traceback:\n\t[string \"print(testset:size())...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/home/gram/torch/install/share/lua/5.1/itorch/main.lua:210: in function </home/gram/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/home/gram/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/home/gram/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/home/gram/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/home/gram/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/home/gram/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00405d50"
     ]
    }
   ],
   "source": [
    "print(testset:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : DoubleTensor - size: 3x32x32\n",
       "  2 : 2\n",
       "}\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(trainset[33])\n",
    "itorch.image(trainset[33][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "redChannel = trainset.data[{ {}, {1}, {}, {}  }] -- this picks {all images, 1st channel, all vertical pixels, all horizontal pixels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10000\n",
       "     1\n",
       "    32\n",
       "    32\n",
       "[torch.LongStorage of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(#redChannel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Channel 1, Mean: 125.83175029297\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 1, Standard Deviation: 63.143400842609\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 2, Mean: 123.26066621094\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 2, Standard Deviation: 62.369209019002\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 3, Mean: 114.03068681641\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Channel 3, Standard Deviation: 66.965808411114\t\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = {} -- store the mean, to normalize the test set in the future\n",
    "stdv  = {} -- store the standard-deviation for the future\n",
    "for i=1,3 do -- over each image channel\n",
    "    mean[i] = trainset.data[{ {}, {i}, {}, {}  }]:mean() -- mean estimation\n",
    "    print('Channel ' .. i .. ', Mean: ' .. mean[i])\n",
    "    trainset.data[{ {}, {i}, {}, {}  }]:add(-mean[i]) -- mean subtraction\n",
    "    \n",
    "    stdv[i] = trainset.data[{ {}, {i}, {}, {}  }]:std() -- std estimation\n",
    "    print('Channel ' .. i .. ', Standard Deviation: ' .. stdv[i])\n",
    "    trainset.data[{ {}, {i}, {}, {}  }]:div(stdv[i]) -- std scaling\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- define the neural network, from above, but using rgb images instead of grey\n",
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialConvolution(3,6,5,5))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.SpatialConvolution(6,16,5,5))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.View(16*5*5))\n",
    "net:add(nn.Linear(16*5*5,120))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.Linear(120,84))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.Linear(84,10))\n",
    "net:add(nn.LogSoftMax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- define a loss function\n",
    "criterion = nn.ClassNLLCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- train the net\n",
    "trainer = nn.StochasticGradient(net, criterion)\n",
    "trainer.learningRate = 0.001\n",
    "trainer.maxIteration = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 2.2049839744928\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.8312180333437\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.6574072105755\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.5603915061671\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 1.4692300418843\t\n",
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 1.4692300418843\t\n",
       "55.95654797554\t\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = torch.Timer()\n",
    "trainer:train(trainset)\n",
    "print(timer:time().real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "horse\t\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- test the net\n",
    "print(classes[testset.label[100]])\n",
    "itorch.image(testset.data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- clean test data\n",
    "testset.data = testset.data:double()\n",
    "for i=1,3 do\n",
    "    testset.data[{ {},{i}, {}, {}}]:add(-mean[i])\n",
    "    testset.data[{ {}, {i}, {}, {}}]:div(stdv[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.073604359943552\t1.3080183656315\t\n"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horse = testset.data[100]\n",
    "print(horse:mean(), horse:std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "horse\t\n"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- predict an image label using the net!!!\n",
    "print(classes[testset.label[100]])\n",
    "itorch.image(testset.data[100])\n",
    "predicted = net:forward(testset.data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.1666\n",
       " 0.0890\n",
       " 0.0801\n",
       " 0.0074\n",
       " 0.0226\n",
       " 0.0010\n",
       " 0.0059\n",
       " 0.0009\n",
       " 0.2909\n",
       " 0.3356\n",
       "[torch.DoubleTensor of size 10]\n",
       "\n",
       "\n"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "--[[ the output of the network is Log-Probabilities. \n",
    "    This is bc of the LogSoftMax() fn at the end of the net.\n",
    "    To convert them to probabilities, you have to take e^x]]--\n",
    "print(predicted:exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--[[ the above are the net's predicted errors that \n",
    "    the image is in each respective category. Next, we'll\n",
    "    put them in order with their names]]--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airplane\t0.16662545879763\t\n",
       "automobile\t0.08898496066225\t\n",
       "bird\t0.080053552117988\t\n",
       "cat\t0.0074395880127836\t\n",
       "deer\t0.022648570906193\t\n",
       "dog\t0.0010336788929553\t\n",
       "frog\t0.0058550936859277\t\n",
       "horse\t0.00086657769986499\t\n",
       "ship\t0.29085730587066\t\n",
       "truck\t0.33563521335374\t\n"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i=1,predicted:size(1) do\n",
    "    print(classes[i], predicted[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- so now let's test the predictions over the whole test dataset\n",
    "-- and use the truth to test the accuracy of the net\n",
    "correct = 0\n",
    "for i = 1, 10000 do\n",
    "    local groundtruth = testset.label[i]\n",
    "    local prediction = net:forward(testset.data[i])\n",
    "    local confidences, indicies = torch.sort(prediction, true)\n",
    "    if groundtruth == indicies[1] then\n",
    "        correct = correct + 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1619\t16.19 % \t\n"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(correct, 100*correct/10000 .. ' % ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- which classes performed well?\n",
    "class_performance = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0}\n",
    "for i = 1, 10000 do\n",
    "    local groundtruth = testset.label[i]\n",
    "    local prediction = net:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        class_performance[groundtruth] = class_performance[groundtruth] + 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airplane\t23.1 %\t\n",
       "automobile\t15.6 %\t\n",
       "bird\t23.9 %\t\n",
       "cat\t0 %\t\n",
       "deer\t0.2 %\t\n",
       "dog\t0 %\t\n",
       "frog\t0.6 %\t\n",
       "horse\t0.1 %\t\n",
       "ship\t95.4 %\t\n",
       "truck\t3 %\t\n"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i = 1, #classes do\n",
    "    print(classes[i], 100*class_performance[i]/1000 .. ' %')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- here is the CUDA code, so I can copy/paste on AWS\n",
    "--[[\n",
    "require 'cunn';\n",
    "net = net:cuda()\n",
    "criterion = criterion:cuda()\n",
    "trainset.data = trainset.data:cuda()\n",
    "trainset.label = trainset.label:cuda()\n",
    "trainer = nn.StochasticGradient(net, criterion)\n",
    "trainer.learningRate = 0.001\n",
    "trainer.maxIteration = 5\n",
    "timer = torch.Timer()\n",
    "trainer:train(trainset)\n",
    "print(timer:time().real)\n",
    "]]--"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
